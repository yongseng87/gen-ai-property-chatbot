import os
import warnings
from dotenv import load_dotenv
import asyncio
import pandas as pd

# LangChain Core
from langchain_openai import ChatOpenAI

# Memory & Chains
from langchain.memory import ConversationBufferMemory
from langchain.chains import RetrievalQA

# Retrieval & Vector Stores
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
from langchain_community.document_loaders import PyPDFLoader

from classifier import classify

# Suppress warnings
warnings.filterwarnings('ignore')

def load_and_process_pdf(pdf_path):
    """Load PDF and process it for Chroma DB"""
    # Knowledge base
    # Load and process multiple PDFs from the examples folder
    pdf_folder = pdf_path
    pdf_files = [os.path.join(pdf_folder, file) for file in os.listdir(pdf_folder) if file.endswith(".pdf")]
    
    all_docs = []
    for pdf_file in pdf_files:
        print(f"Processing file: {pdf_file}")
        loader = PyPDFLoader(pdf_file)
        pages = loader.load()
        
        text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
        )
        docs = text_splitter.split_documents(pages)
        all_docs.extend(docs)
    
    print(f"üìù Total text chunks from all PDFs: {len(all_docs)}")
    
    # Create embeddings
    embeddings_pdf = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
    
    # Clear any existing chroma database (commented out to prevent errors on rerun)
    db_path = "./pdf_knowledge_base"
    # if os.path.exists(db_path):
    #     shutil.rmtree(db_path)
    #     print("üßπ Cleared existing database")
    
    # Create Chroma vector store
    print("üîç Creating vector embeddings...")
    vectorstore_pdf = Chroma.from_documents(
        documents=all_docs,
        embedding=embeddings_pdf,
        persist_directory=db_path)
    
    # Persist the database
    vectorstore_pdf.persist()
    print(f"üíæ Vector database saved to: {db_path}")
    
    return vectorstore_pdf


def create_pdf_qa_system(vectorstore_pdf, llm):
    """Create Q&A system for PDF documents"""
    
    # Create retrieval QA chain
    qa_chain_pdf = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore_pdf.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}  # Return top 3 relevant chunks
        ),
        return_source_documents=True
    )
    
    print("‚úÖ PDF Q&A system created successfully")
    return qa_chain_pdf


def create_csv_agent(csv_path, llm):
    """Create agent for CSV documents"""
    
    df = pd.read_csv(csv_path)
    agent = create_pandas_dataframe_agent(
        llm=llm,
        df=df,
        verbose=True,
        agent_type="openai-tools",
        allow_dangerous_code=True,
    )
    print("‚úÖ CSV Agent created successfully")
    return agent


class PropertySupportBot:
    def __init__(self):
        # Load environment variables
        load_dotenv()
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables.")
            
        try:
            self.llm = ChatOpenAI(
                model="gpt-4o-mini", 
                temperature=0.1, 
                api_key=self.openai_api_key,
                max_retries=3,
                request_timeout=30
            )
            self.embeddings = OpenAIEmbeddings(
                openai_api_key=self.openai_api_key,
                max_retries=3,
                request_timeout=30
            )
        except Exception as e:
            print(f"Error initializing OpenAI models: {e}")
            raise
        
        try:
            # Knowledge base
            self.vectorstore = load_and_process_pdf("property_data_generator")
            
            # Memory for conversations
            self.memory = ConversationBufferMemory()
            
            # QA chain for policies
            self.qa_chain = create_pdf_qa_system(self.vectorstore, self.llm)
            # CSV tools
            csv_path = "property_database_v2.csv"
            self.csv_agent = create_csv_agent(csv_path, self.llm)
            # Keep a direct pandas DataFrame for fast stats
            self.data_df = pd.read_csv(csv_path)
            # Precompute canonical lookups
            self.known_towns = set(str(x).strip().upper() for x in self.data_df["town"].dropna().unique())
            self.known_property_types = set(str(x).strip().upper() for x in self.data_df["property_type"].dropna().unique())
            self.known_rental_types = set(str(x).strip().upper() for x in self.data_df["rental_type"].dropna().unique())
        except Exception as e:
            print(f"Error initializing knowledge base: {e}")
            raise
    
    def process_query(self, query: str):
        """Process user query based on category classification (synchronous version)"""
        
        print(f"üîµ INPUT TO SUPPORT BOT:")
        print(f"Query: {query}")

        try:
            # Classify the query with timeout
            try:
                # Check if we're already in an event loop
                try:
                    loop = asyncio.get_running_loop()
                    # We're in an event loop, use run_in_executor
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, asyncio.wait_for(classify(query), timeout=10.0))
                        classification = future.result(timeout=15.0)  # Give extra time for the executor
                except RuntimeError:
                    # No event loop running, safe to use asyncio.run
                    classification = asyncio.run(asyncio.wait_for(classify(query), timeout=10.0))
                
                module = classification['classifications'][0]['module']
                print(f"üéØ Classification: {module}")
            except asyncio.TimeoutError:
                print("‚è∞ Classification timeout, using fallback")
                module = "general_support"
            except Exception as e:
                print(f"‚ùå Classification error: {e}, using fallback")
                module = "general_support"
            
            if module == "information_retrieval":
                print("\nüîµ HANDLING INFORMATION RETRIEVAL QUERY...")
                try:
                    result = self.qa_chain.invoke(query)
                    print(f"Answer: {result['result']}")
                    if result.get('source_documents'):
                        print(f"üìÑ Sources: Page {result['source_documents'][0].metadata.get('page', 'Unknown')} of PDF")
                        print(f"üìù Source Text Preview: {result['source_documents'][0].page_content[:150]}...")
                    return result['result']
                except Exception as e:
                    print(f"‚ùå PDF QA error: {e}")
                    return self._fallback_response(query, "PDF knowledge base")
                    
            elif module in ("property_data_analysis", "property_statistics", "property statistic queries"):
                print("\nüîµ HANDLING PROPERTY DATA ANALYSIS QUERY...")
                try:
                    # Try fast pandas-based statistics first
                    stats_answer = self._answer_property_statistics(query)
                    if stats_answer:
                        return stats_answer
                    # Fallback to agent
                    result = self.csv_agent.invoke(query)
                    print(f"Analysis Result: {result['output']}")
                    return result['output']
                except Exception as e:
                    print(f"‚ùå CSV analysis error: {e}")
                    return self._fallback_response(query, "property data analysis")
                    
            else:
                print("\nüîµ HANDLING GENERAL QUERY...")
                try:
                    # Use simple LLM for general queries
                    response = self.llm.invoke(query)
                    return response.content
                except Exception as e:
                    print(f"‚ùå General query error: {e}")
                    return self._fallback_response(query, "general support")
                
        except Exception as e:
            print(f"‚ùå Critical error in process_query: {e}")
            return f"I apologize, but I encountered an error while processing your query: '{query}'. Please try rephrasing your question or contact support if the issue persists."

    async def process_query_async(self, query: str):
        """Process user query based on category classification (asynchronous version)"""
        
        print(f"üîµ INPUT TO SUPPORT BOT (ASYNC):")
        print(f"Query: {query}")

        try:
            # Classify the query with timeout
            try:
                classification = await asyncio.wait_for(classify(query), timeout=10.0)
                module = classification['classifications'][0]['module']
                print(f"üéØ Classification: {module}")
            except asyncio.TimeoutError:
                print("‚è∞ Classification timeout, using fallback")
                module = "general_support"
            except Exception as e:
                print(f"‚ùå Classification error: {e}, using fallback")
                module = "general_support"
            
            if module == "information_retrieval":
                print("\nüîµ HANDLING INFORMATION RETRIEVAL QUERY...")
                try:
                    # Run the synchronous invoke in a thread pool to avoid blocking
                    loop = asyncio.get_event_loop()
                    result = await loop.run_in_executor(None, self.qa_chain.invoke, query)
                    print(f"Answer: {result['result']}")
                    if result.get('source_documents'):
                        print(f"üìÑ Sources: Page {result['source_documents'][0].metadata.get('page', 'Unknown')} of PDF")
                        print(f"üìù Source Text Preview: {result['source_documents'][0].page_content[:150]}...")
                    return result['result']
                except Exception as e:
                    print(f"‚ùå PDF QA error: {e}")
                    return self._fallback_response(query, "PDF knowledge base")
                    
            elif module in ("property_data_analysis", "property_statistics", "property statistic queries"):
                print("\nüîµ HANDLING PROPERTY DATA ANALYSIS QUERY...")
                try:
                    # Try fast pandas-based statistics first
                    loop = asyncio.get_event_loop()
                    stats_answer = await loop.run_in_executor(None, self._answer_property_statistics, query)
                    if stats_answer:
                        return stats_answer
                    # Fallback to agent (run in executor)
                    result = await loop.run_in_executor(None, self.csv_agent.invoke, query)
                    print(f"Analysis Result: {result['output']}")
                    return result['output']
                except Exception as e:
                    print(f"‚ùå CSV analysis error: {e}")
                    return self._fallback_response(query, "property data analysis")
                    
            else:
                print("\nüîµ HANDLING GENERAL QUERY...")
                try:
                    # Run the synchronous invoke in a thread pool to avoid blocking
                    loop = asyncio.get_event_loop()
                    response = await loop.run_in_executor(None, self.llm.invoke, query)
                    return response.content
                except Exception as e:
                    print(f"‚ùå General query error: {e}")
                    return self._fallback_response(query, "general support")
                
        except Exception as e:
            print(f"‚ùå Critical error in process_query_async: {e}")
            return f"I apologize, but I encountered an error while processing your query: '{query}'. Please try rephrasing your question or contact support if the issue persists."
    
    def _fallback_response(self, query: str, context: str):
        """Provide a fallback response when API calls fail"""
        return f"I'm having trouble accessing the {context} right now. Your question '{query}' seems to be about property-related matters. Please try again in a moment, or contact our support team for immediate assistance."

    def _answer_property_statistics(self, query: str) -> str:
        """Lightweight parser to answer basic filtered statistics directly from pandas.

        Supports aggregations over columns like rental_price or floor_area_sqm,
        filters over town, property_type, rental_type, lease_commence_year,
        and simple group by 'by town'/'by property type'/'by rental type'.
        Returns empty string if unable to confidently handle.
        """
        try:
            if not hasattr(self, "data_df") or self.data_df is None:
                return ""
            text = str(query).strip().lower()

            df = self.data_df.copy()

            # Determine metric
            metric_col = None
            if any(k in text for k in ["price", "rent", "rental"]):
                metric_col = "rental_price"
            elif any(k in text for k in ["area", "size", "sqm"]):
                metric_col = "floor_area_sqm"
            # default to rental_price if asking average without metric
            if metric_col is None and any(k in text for k in ["avg", "average", "mean", "median", "min", "max", "count"]):
                metric_col = "rental_price"

            # Determine aggregation
            agg = None
            if any(k in text for k in ["avg", "average", "mean"]):
                agg = "mean"
            elif "median" in text:
                agg = "median"
            elif "min" in text or "lowest" in text or "cheapest" in text:
                agg = "min"
            elif "max" in text or "highest" in text or "most expensive" in text:
                agg = "max"
            elif "count" in text or "how many" in text:
                agg = "count"

            # Filters: town
            town_match = None
            for town in self.known_towns:
                if town and town.lower() in text:
                    town_match = town
                    break
            if town_match:
                df = df[df["town"].str.upper() == town_match]

            # Filters: property_type
            prop_match = None
            for p in self.known_property_types:
                if p and p.lower() in text:
                    prop_match = p
                    break
            if prop_match:
                df = df[df["property_type"].str.upper() == prop_match]

            # Filters: rental_type (e.g., 2 bedroom, 3 room)
            import re
            bed_match = re.search(r"(\d+)\s*bed(room)?", text)
            room_match = re.search(r"(\d+)\s*room", text)
            rental_type_match = None
            if bed_match:
                rental_type_match = f"{bed_match.group(1)} BEDROOM"
            elif room_match:
                n = room_match.group(1)
                rental_type_match = f"{n} ROOM" if n.isdigit() else None
            if rental_type_match:
                df = df[df["rental_type"].str.upper().str.contains(rental_type_match)]

            # Filters: year (lease_commence_year)
            year_match = re.search(r"(19|20)\d{2}", text)
            if year_match and "lease" in text:
                y = int(year_match.group(0))
                if "lease_commence_year" in df.columns:
                    df = df[df["lease_commence_year"] == y]

            # Group by
            group_col = None
            if "by town" in text:
                group_col = "town"
            elif "by property type" in text or "by property_type" in text:
                group_col = "property_type"
            elif "by rental type" in text or "by bedroom" in text:
                group_col = "rental_type"

            # If no rows after filtering
            if df.empty:
                return "I couldn't find matching records for your filters in the dataset."

            # If only count requested
            if agg == "count" and group_col is None:
                return f"Count: {len(df)}"

            # If group by requested
            if group_col:
                if agg is None:
                    agg = "mean" if metric_col else None
                if agg and metric_col:
                    grouped = df.groupby(group_col)[metric_col].agg(agg).sort_values(ascending=False)
                    head = grouped.head(20)
                    return head.to_string()
                else:
                    grouped = df.groupby(group_col).size().sort_values(ascending=False)
                    head = grouped.head(20)
                    return head.to_string()

            # Single value aggregation
            if agg and metric_col:
                val = getattr(df[metric_col], agg)()
                return f"{agg} of {metric_col}: {round(float(val), 2)}"

            # If user asked list or distribution without explicit agg
            if "list" in text or "show" in text or "distribution" in text:
                preview_cols = [c for c in ["town", "property_type", "rental_type", "rental_price", "floor_area_sqm"] if c in df.columns]
                preview = df[preview_cols].head(20)
                return preview.to_string(index=False)

            return ""
        except Exception as e:
            print(f"_answer_property_statistics error: {e}")
            return ""

if __name__ == "__main__":
    # Load environment variables
    load_dotenv()

    # Verify API key
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        raise ValueError("OPENAI_API_KEY not found in environment variables.")
    # Initialize the complete system
    print("üöÄ Initializing Complete Property Support Bot...")
    support_bot = PropertySupportBot()

    # Test various query types
    test_queries = [
        "what is the mean price of HDB flats in Bishan?",
        "Do I need to pay for repairs in my rental unit?",
        "how to invest in stocks for beginners?",
        # "I‚Äôm renting a landed house currently. Can I use the unit to conduct my home business?",
        # "I‚Äôm renting a condominium unit. Am I allowed to keep pets?",
        # "Am I allowed to cook in the house?",
        # "Who is responsible for servicing and maintaining the air-con?",
        # "Can you recommend me an air-con cleaning contractor?",
        # "Who should be responsible for paying the condo management fees?",
        # "I‚Äôm looking for a two room HDB unit to rent in Hougang. Can you recommend me some available units with monthly rental below $2,200?",
        # "how far is the unit 998B buangkok cres away from the MRT and which station is it?",
        # "are rental prices in hougang cheaper than rental prices in punggol?",
        # "are rental prices in JB cheaper than rental prices in singapore?",
        # "what is the average rental price of landed houses in singapore?",
        # "recommend me a place to rent that is near to Toa Payoh MRT station",
        # "recommend me a place to rent that is near to Ai Tong School",
        # "I'm looking for a high floor, 2 room unit to rent in yishun. Recommend me some places",
        # "recommend me a good place to stay in singapore",
        # "I am a foreigner and have just lost my job. However, my rental period has not finished but my work permit will be expiring. How can I terminate my rental agreement and are there any penalties?",
        # "What is the interest rate for late payment of rent?",
        # "I'm currently bankrupt and unable to pay the rent that I have owed, can I still stay at the premises and what do I have to do?"
        # "what is the price difference for renting 1 bedroom in 2024 versus 2025?",
        # "what is the cheapest rental price for houses in Orchard",
        # "what is the highest rental price for a unit in Sengkang?",
        # "how many 4 room HDB units are available for rent in Bukit Merah?",
        # "what is the range of rental prices for houses in June 2024.",
        # "what is the average size of 3 room HDB flats?"        
    ]

    for query in test_queries:
        print(f"{'='*60}")
        print("PROCESSING NEW QUERY...")
        print(f"{'='*60}")
        
        support_bot.process_query(query)
